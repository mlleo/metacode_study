{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b54f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3e03fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\aistudy\\metacode_study\\06-DocumentLoader\\data\\KDS140000Structure.pdf\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = r\"D:\\aistudy\\metacode_study\\06-DocumentLoader\\data\\KDS140000Structure.pdf\"\n",
    "print(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9176891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PDF → LaTeX 변환 파이프라인 (메모리 효율적)\n",
    "수식이 포함된 PDF를 LaTeX로 변환하여 RAG에 활용\n",
    "\n",
    "특징:\n",
    "1. 이미지를 디스크에 저장하지 않고 메모리에서 처리\n",
    "2. 각 컴포넌트를 독립적으로 사용 가능\n",
    "3. 스트리밍 방식으로 페이지별 처리\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import fitz  # PyMuPDF\n",
    "from typing import Generator, List, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. 이미지 추출 컴포넌트\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class PageImage:\n",
    "    \"\"\"페이지 이미지 데이터\"\"\"\n",
    "    page_num: int\n",
    "    image: Image.Image\n",
    "    width: int\n",
    "    height: int\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.width, self.height = self.image.size\n",
    "\n",
    "\n",
    "class PDFImageExtractor:\n",
    "    \"\"\"PDF에서 이미지를 추출하는 컴포넌트\"\"\"\n",
    "    \n",
    "    def __init__(self, dpi: int = 300):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dpi: 이미지 해상도 (144=zoom 2.0, 216=zoom 3.0, 300=zoom 4.17)\n",
    "        \"\"\"\n",
    "        self.dpi = dpi\n",
    "        self.zoom = dpi / 72.0  # 72 DPI가 기본\n",
    "    \n",
    "    def extract_page(self, pdf_path: str, page_num: int) -> PageImage:\n",
    "        \"\"\"\n",
    "        단일 페이지를 이미지로 변환 (메모리에만 보관)\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: PDF 파일 경로\n",
    "            page_num: 페이지 번호 (1부터 시작)\n",
    "        \n",
    "        Returns:\n",
    "            PageImage 객체\n",
    "        \"\"\"\n",
    "        doc = fitz.open(pdf_path)\n",
    "        \n",
    "        try:\n",
    "            # 페이지 추출 (0-based index)\n",
    "            page = doc[page_num - 1]\n",
    "            \n",
    "            # 이미지로 렌더링\n",
    "            mat = fitz.Matrix(self.zoom, self.zoom)\n",
    "            pix = page.get_pixmap(matrix=mat, alpha=False)\n",
    "            \n",
    "            # PIL Image로 변환 (디스크 저장 없음)\n",
    "            img_bytes = pix.tobytes(\"png\")\n",
    "            image = Image.open(BytesIO(img_bytes))\n",
    "            \n",
    "            return PageImage(\n",
    "                page_num=page_num,\n",
    "                image=image,\n",
    "                width=image.size[0],\n",
    "                height=image.size[1]\n",
    "            )\n",
    "        \n",
    "        finally:\n",
    "            doc.close()\n",
    "    \n",
    "    def extract_pages(\n",
    "        self, \n",
    "        pdf_path: str, \n",
    "        page_range: Optional[tuple] = None\n",
    "    ) -> Generator[PageImage, None, None]:\n",
    "        \"\"\"\n",
    "        여러 페이지를 스트리밍 방식으로 추출\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: PDF 파일 경로\n",
    "            page_range: (시작, 끝) 페이지 번호. None이면 전체\n",
    "        \n",
    "        Yields:\n",
    "            PageImage 객체\n",
    "        \"\"\"\n",
    "        doc = fitz.open(pdf_path)\n",
    "        \n",
    "        try:\n",
    "            total_pages = len(doc)\n",
    "            \n",
    "            if page_range is None:\n",
    "                start, end = 1, total_pages\n",
    "            else:\n",
    "                start, end = page_range\n",
    "                end = min(end, total_pages)\n",
    "            \n",
    "            print(f\"총 {total_pages}페이지 중 {start}~{end} 페이지 처리\")\n",
    "            \n",
    "            for page_num in range(start, end + 1):\n",
    "                page = doc[page_num - 1]\n",
    "                \n",
    "                mat = fitz.Matrix(self.zoom, self.zoom)\n",
    "                pix = page.get_pixmap(matrix=mat, alpha=False)\n",
    "                \n",
    "                img_bytes = pix.tobytes(\"png\")\n",
    "                image = Image.open(BytesIO(img_bytes))\n",
    "                \n",
    "                yield PageImage(\n",
    "                    page_num=page_num,\n",
    "                    image=image,\n",
    "                    width=image.size[0],\n",
    "                    height=image.size[1]\n",
    "                )\n",
    "        \n",
    "        finally:\n",
    "            doc.close()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. OCR 컴포넌트\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class OCRResult:\n",
    "    \"\"\"OCR 결과 데이터\"\"\"\n",
    "    page_num: int\n",
    "    text: str\n",
    "    confidence: Optional[float] = None\n",
    "    processing_time: Optional[float] = None\n",
    "\n",
    "\n",
    "class NougatOCR:\n",
    "    \"\"\"Nougat을 사용한 OCR 컴포넌트\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str = \"facebook/nougat-base\",\n",
    "        use_gpu: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: Nougat 모델 이름\n",
    "            use_gpu: GPU 사용 여부\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.use_gpu = use_gpu and torch.cuda.is_available()\n",
    "        self.model = None\n",
    "        self.device = \"cuda\" if self.use_gpu else \"cpu\"\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"모델을 메모리에 로드\"\"\"\n",
    "        if self.model is not None:\n",
    "            return\n",
    "        \n",
    "        print(f\"Nougat 모델 로딩 중... (device: {self.device})\")\n",
    "        \n",
    "        try:\n",
    "            from nougat import NougatModel\n",
    "            self.model = NougatModel.from_pretrained(self.model_name)\n",
    "            self.model = self.model.to(self.device)\n",
    "            self.model.eval()\n",
    "            print(\"✓ 모델 로딩 완료\")\n",
    "        \n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Nougat이 설치되지 않았습니다.\\n\"\n",
    "                \"설치: pip install nougat-ocr\"\n",
    "            )\n",
    "    \n",
    "    def process_image(self, image: Image.Image) -> str:\n",
    "        \"\"\"\n",
    "        이미지에서 LaTeX 텍스트 추출\n",
    "        \n",
    "        Args:\n",
    "            image: PIL Image 객체\n",
    "        \n",
    "        Returns:\n",
    "            LaTeX/Markdown 형식의 텍스트\n",
    "        \"\"\"\n",
    "        import time\n",
    "        from nougat.postprocessing import markdown_compatible\n",
    "        \n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                # inference 호출 (메모리에서 직접 처리)\n",
    "                output = self.model.inference(image=image)\n",
    "                output = markdown_compatible(output)\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            print(f\"  OCR 완료 ({processing_time:.2f}초)\")\n",
    "            \n",
    "            return output\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  OCR 오류: {e}\")\n",
    "            # CLI fallback이 필요한 경우\n",
    "            raise RuntimeError(\n",
    "                f\"OCR 처리 실패: {e}\\n\"\n",
    "                \"CLI 사용을 고려하세요: nougat pdf_file.pdf -o output\"\n",
    "            )\n",
    "    \n",
    "    def process_page_image(self, page_image: PageImage) -> OCRResult:\n",
    "        \"\"\"\n",
    "        PageImage 객체를 처리\n",
    "        \n",
    "        Args:\n",
    "            page_image: PageImage 객체\n",
    "        \n",
    "        Returns:\n",
    "            OCRResult 객체\n",
    "        \"\"\"\n",
    "        import time\n",
    "        \n",
    "        print(f\"페이지 {page_image.page_num} OCR 처리 중...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        text = self.process_image(page_image.image)\n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        return OCRResult(\n",
    "            page_num=page_image.page_num,\n",
    "            text=text,\n",
    "            processing_time=processing_time\n",
    "        )\n",
    "    \n",
    "    def unload_model(self):\n",
    "        \"\"\"모델을 메모리에서 제거\"\"\"\n",
    "        if self.model is not None:\n",
    "            del self.model\n",
    "            self.model = None\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            print(\"✓ 모델 언로드 완료\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. 문서 로더 컴포넌트\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class Document:\n",
    "    \"\"\"RAG에서 사용할 문서 객체\"\"\"\n",
    "    page_content: str\n",
    "    metadata: Dict\n",
    "    \n",
    "    def __repr__(self):\n",
    "        preview = self.page_content[:100].replace('\\n', ' ')\n",
    "        return f\"Document(page={self.metadata.get('page')}, content='{preview}...')\"\n",
    "\n",
    "\n",
    "class PDFLaTeXLoader:\n",
    "    \"\"\"PDF를 LaTeX로 변환하여 로드하는 컴포넌트\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        extractor: PDFImageExtractor,\n",
    "        ocr: NougatOCR\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            extractor: PDFImageExtractor 인스턴스\n",
    "            ocr: NougatOCR 인스턴스\n",
    "        \"\"\"\n",
    "        self.extractor = extractor\n",
    "        self.ocr = ocr\n",
    "    \n",
    "    def load_page(self, pdf_path: str, page_num: int) -> Document:\n",
    "        \"\"\"\n",
    "        단일 페이지를 로드\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: PDF 파일 경로\n",
    "            page_num: 페이지 번호 (1부터 시작)\n",
    "        \n",
    "        Returns:\n",
    "            Document 객체\n",
    "        \"\"\"\n",
    "        # 1. 이미지 추출 (메모리)\n",
    "        page_image = self.extractor.extract_page(pdf_path, page_num)\n",
    "        \n",
    "        # 2. OCR 처리 (메모리)\n",
    "        ocr_result = self.ocr.process_page_image(page_image)\n",
    "        \n",
    "        # 3. Document 생성\n",
    "        document = Document(\n",
    "            page_content=ocr_result.text,\n",
    "            metadata={\n",
    "                'source': pdf_path,\n",
    "                'page': page_num,\n",
    "                'width': page_image.width,\n",
    "                'height': page_image.height,\n",
    "                'processing_time': ocr_result.processing_time\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return document\n",
    "    \n",
    "    def load_pages(\n",
    "        self, \n",
    "        pdf_path: str, \n",
    "        page_range: Optional[tuple] = None\n",
    "    ) -> Generator[Document, None, None]:\n",
    "        \"\"\"\n",
    "        여러 페이지를 스트리밍 방식으로 로드\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: PDF 파일 경로\n",
    "            page_range: (시작, 끝) 페이지 번호\n",
    "        \n",
    "        Yields:\n",
    "            Document 객체\n",
    "        \"\"\"\n",
    "        # OCR 모델 로드 (한 번만)\n",
    "        self.ocr.load_model()\n",
    "        \n",
    "        try:\n",
    "            # 페이지별로 스트리밍 처리\n",
    "            for page_image in self.extractor.extract_pages(pdf_path, page_range):\n",
    "                # OCR 처리\n",
    "                ocr_result = self.ocr.process_page_image(page_image)\n",
    "                \n",
    "                # Document 생성\n",
    "                document = Document(\n",
    "                    page_content=ocr_result.text,\n",
    "                    metadata={\n",
    "                        'source': pdf_path,\n",
    "                        'page': page_image.page_num,\n",
    "                        'width': page_image.width,\n",
    "                        'height': page_image.height,\n",
    "                        'processing_time': ocr_result.processing_time\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                yield document\n",
    "        \n",
    "        finally:\n",
    "            # 메모리 정리\n",
    "            self.ocr.unload_model()\n",
    "    \n",
    "    def load_all(\n",
    "        self, \n",
    "        pdf_path: str, \n",
    "        page_range: Optional[tuple] = None\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"\n",
    "        모든 페이지를 한 번에 로드 (메모리 사용량 주의)\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: PDF 파일 경로\n",
    "            page_range: (시작, 끝) 페이지 번호\n",
    "        \n",
    "        Returns:\n",
    "            Document 객체 리스트\n",
    "        \"\"\"\n",
    "        return list(self.load_pages(pdf_path, page_range))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. 사용 예제\n",
    "# ============================================================\n",
    "\n",
    "def example_single_page(pdf_path: str, page_num: int = 1, dpi: int = 300, use_gpu: bool = True):\n",
    "    \"\"\"\n",
    "    단일 페이지 처리 예제\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: PDF 파일 경로\n",
    "        page_num: 페이지 번호 (기본값: 1)\n",
    "        dpi: 이미지 해상도 (기본값: 300)\n",
    "        use_gpu: GPU 사용 여부 (기본값: True)\n",
    "    \n",
    "    Returns:\n",
    "        Document 객체\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"예제 1: 단일 페이지 처리\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # 컴포넌트 초기화\n",
    "    extractor = PDFImageExtractor(dpi=dpi)\n",
    "    extractor.extract_page(pdf_path=pdf_path, page_num=page_num)\n",
    "    ocr = NougatOCR(use_gpu=use_gpu)\n",
    "    loader = PDFLaTeXLoader(extractor, ocr)\n",
    "    \n",
    "    # 페이지 로드\n",
    "    document = loader.load_page(pdf_path, page_num)\n",
    "    \n",
    "    print(f\"\\n문서 정보:\")\n",
    "    print(f\"  페이지: {document.metadata['page']}\")\n",
    "    print(f\"  크기: {document.metadata['width']}x{document.metadata['height']}\")\n",
    "    print(f\"  처리시간: {document.metadata['processing_time']:.2f}초\")\n",
    "    print(f\"\\n내용 미리보기:\")\n",
    "    print(document.page_content[:500])\n",
    "    \n",
    "    return document\n",
    "\n",
    "\n",
    "def example_streaming():\n",
    "    \"\"\"스트리밍 방식 처리 예제 (메모리 효율적)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"예제 2: 스트리밍 방식 처리 (메모리 효율적)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # 컴포넌트 초기화\n",
    "    extractor = PDFImageExtractor(dpi=300)\n",
    "    ocr = NougatOCR(use_gpu=True)\n",
    "    loader = PDFLaTeXLoader(extractor, ocr)\n",
    "    \n",
    "    # 페이지별로 처리 (메모리에 한 번에 하나만 보관)\n",
    "    pdf_path = \"your_file.pdf\"\n",
    "    page_range = (1, 5)  # 1-5페이지\n",
    "    \n",
    "    for document in loader.load_pages(pdf_path, page_range):\n",
    "        print(f\"\\n페이지 {document.metadata['page']} 로드 완료\")\n",
    "        print(f\"  내용 길이: {len(document.page_content)} 문자\")\n",
    "        \n",
    "        # 여기서 바로 벡터DB에 저장 가능\n",
    "        # vector_db.add_document(document)\n",
    "        \n",
    "        # 또는 파일로 저장\n",
    "        with open(f\"page_{document.metadata['page']}.md\", 'w', encoding='utf-8') as f:\n",
    "            f.write(document.page_content)\n",
    "\n",
    "\n",
    "def example_batch():\n",
    "    \"\"\"일괄 처리 예제\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"예제 3: 일괄 처리\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # 컴포넌트 초기화\n",
    "    extractor = PDFImageExtractor(dpi=300)\n",
    "    ocr = NougatOCR(use_gpu=True)\n",
    "    loader = PDFLaTeXLoader(extractor, ocr)\n",
    "    \n",
    "    # 모든 페이지 로드\n",
    "    pdf_path = \"your_file.pdf\"\n",
    "    documents = loader.load_all(pdf_path, page_range=(1, 3))\n",
    "    \n",
    "    print(f\"\\n총 {len(documents)}개 문서 로드 완료\")\n",
    "    \n",
    "    for doc in documents:\n",
    "        print(f\"  - {doc}\")\n",
    "    \n",
    "    return documents\n",
    "\n",
    "\n",
    "def example_with_langchain():\n",
    "    \"\"\"LangChain과 통합 예제\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"예제 4: LangChain RAG 파이프라인\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # 컴포넌트 초기화\n",
    "    extractor = PDFImageExtractor(dpi=300)\n",
    "    ocr = NougatOCR(use_gpu=True)\n",
    "    loader = PDFLaTeXLoader(extractor, ocr)\n",
    "    \n",
    "    pdf_path = \"your_file.pdf\"\n",
    "    \n",
    "    # 스트리밍으로 처리하면서 LangChain에 통합\n",
    "    documents_for_langchain = []\n",
    "    \n",
    "    for document in loader.load_pages(pdf_path, page_range=(1, 10)):\n",
    "        # LangChain Document 형식으로 변환 가능\n",
    "        documents_for_langchain.append(document)\n",
    "    \n",
    "    # 텍스트 스플리터 적용 예제\n",
    "    print(\"\\n텍스트 스플릿 준비 완료\")\n",
    "    print(f\"총 {len(documents_for_langchain)}개 문서\")\n",
    "    \n",
    "    # 다음 단계:\n",
    "    # from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    # splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "    # splits = splitter.split_documents(documents_for_langchain)\n",
    "    \n",
    "    return documents_for_langchain\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 사용하고 싶은 예제 선택\n",
    "    \n",
    "    # 1. 단일 페이지\n",
    "    # example_single_page()\n",
    "    \n",
    "    # 2. 스트리밍 (권장 - 메모리 효율적)\n",
    "    # example_streaming()\n",
    "    \n",
    "    # 3. 일괄 처리\n",
    "    # example_batch()\n",
    "    \n",
    "    # 4. LangChain 통합\n",
    "    # example_with_langchain()\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c5c3fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "예제 1: 단일 페이지 처리\n",
      "============================================================\n",
      "\n",
      "페이지 34 OCR 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:108: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform\n",
      "  super().__init__(always_apply=always_apply, p=p)\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:42: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform\n",
      "  super().__init__(always_apply=always_apply, p=p)\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:76: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform\n",
      "  super().__init__(always_apply=always_apply, p=p)\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:123: UserWarning: Argument(s) 'cval' are not valid for transform Affine\n",
      "  alb.Affine(shear={\"x\": (0, 3), \"y\": (-3, 0)}, cval=(255, 255, 255), p=0.03),\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:124: UserWarning: Argument(s) 'value' are not valid for transform ShiftScaleRotate\n",
      "  alb.ShiftScaleRotate(\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:134: UserWarning: Argument(s) 'value' are not valid for transform GridDistortion\n",
      "  alb.GridDistortion(\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:143: UserWarning: Argument(s) 'always_apply, cval' are not valid for transform Affine\n",
      "  alb.Affine(\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:146: UserWarning: Argument(s) 'alpha_affine, value' are not valid for transform ElasticTransform\n",
      "  alb.ElasticTransform(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "1 validation error for InitSchema\ncompression_type\n  Input should be 'jpeg' or 'webp' [type=literal_error, input_value=95, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.10/v/literal_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\albumentations\\core\\validation.py:67\u001b[39m, in \u001b[36mValidatedTransformMeta._validate_parameters\u001b[39m\u001b[34m(schema_cls, full_kwargs, param_names, strict)\u001b[39m\n\u001b[32m     66\u001b[39m schema_kwargs[\u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m] = strict\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m config = \u001b[43mschema_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mschema_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m validated_kwargs = config.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\pydantic\\main.py:214\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    213\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for InitSchema\ncompression_type\n  Input should be 'jpeg' or 'webp' [type=literal_error, input_value=95, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.10/v/literal_error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m doc = \u001b[43mexample_single_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFILE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage_num\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m34\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 401\u001b[39m, in \u001b[36mexample_single_page\u001b[39m\u001b[34m(pdf_path, page_num, dpi, use_gpu)\u001b[39m\n\u001b[32m    398\u001b[39m loader = PDFLaTeXLoader(extractor, ocr)\n\u001b[32m    400\u001b[39m \u001b[38;5;66;03m# 페이지 로드\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m document = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m문서 정보:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  페이지: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument.metadata[\u001b[33m'\u001b[39m\u001b[33mpage\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 297\u001b[39m, in \u001b[36mPDFLaTeXLoader.load_page\u001b[39m\u001b[34m(self, pdf_path, page_num)\u001b[39m\n\u001b[32m    294\u001b[39m page_image = \u001b[38;5;28mself\u001b[39m.extractor.extract_page(pdf_path, page_num)\n\u001b[32m    296\u001b[39m \u001b[38;5;66;03m# 2. OCR 처리 (메모리)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m ocr_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mocr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_page_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[38;5;66;03m# 3. Document 생성\u001b[39;00m\n\u001b[32m    300\u001b[39m document = Document(\n\u001b[32m    301\u001b[39m     page_content=ocr_result.text,\n\u001b[32m    302\u001b[39m     metadata={\n\u001b[32m   (...)\u001b[39m\u001b[32m    308\u001b[39m     }\n\u001b[32m    309\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 232\u001b[39m, in \u001b[36mNougatOCR.process_page_image\u001b[39m\u001b[34m(self, page_image)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m페이지 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_image.page_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m OCR 처리 중...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    230\u001b[39m start_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m text = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_image\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m processing_time = time.time() - start_time\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m OCRResult(\n\u001b[32m    236\u001b[39m     page_num=page_image.page_num,\n\u001b[32m    237\u001b[39m     text=text,\n\u001b[32m    238\u001b[39m     processing_time=processing_time\n\u001b[32m    239\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 191\u001b[39m, in \u001b[36mNougatOCR.process_image\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[33;03m이미지에서 LaTeX 텍스트 추출\u001b[39;00m\n\u001b[32m    183\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    188\u001b[39m \u001b[33;03m    LaTeX/Markdown 형식의 텍스트\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnougat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpostprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m markdown_compatible\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28mself\u001b[39m.load_model()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mDonut\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mCopyright (c) 2022-present NAVER Corp.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mMIT License\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03mCopyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NougatConfig, NougatModel\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NougatDataset\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\model.py:34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig, PreTrainedModel\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnougat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpostprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m postprocess\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnougat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_transform, test_transform\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSwinEncoder\u001b[39;00m(nn.Module):\n\u001b[32m     38\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m    Encoder based on SwinTransformer\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    Set the initial weights and configuration with a pretrained SwinTransformer and then\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m \u001b[33;03m                      otherwise, `swin_base_patch4_window12_384` will be set (using `timm`).\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:158\u001b[39m\n\u001b[32m    114\u001b[39m         img[img < \u001b[38;5;28mself\u001b[39m.lower] = \u001b[38;5;28mself\u001b[39m.value\n\u001b[32m    115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[32m    118\u001b[39m train_transform = alb_wrapper(\n\u001b[32m    119\u001b[39m     alb.Compose(\n\u001b[32m    120\u001b[39m         [\n\u001b[32m    121\u001b[39m             Bitmap(p=\u001b[32m0.05\u001b[39m),\n\u001b[32m    122\u001b[39m             alb.OneOf([Erosion((\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m)), Dilation((\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m))], p=\u001b[32m0.02\u001b[39m),\n\u001b[32m    123\u001b[39m             alb.Affine(shear={\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m: (-\u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m)}, cval=(\u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m), p=\u001b[32m0.03\u001b[39m),\n\u001b[32m    124\u001b[39m             alb.ShiftScaleRotate(\n\u001b[32m    125\u001b[39m                 shift_limit_x=(\u001b[32m0\u001b[39m, \u001b[32m0.04\u001b[39m),\n\u001b[32m    126\u001b[39m                 shift_limit_y=(\u001b[32m0\u001b[39m, \u001b[32m0.03\u001b[39m),\n\u001b[32m    127\u001b[39m                 scale_limit=(-\u001b[32m0.15\u001b[39m, \u001b[32m0.03\u001b[39m),\n\u001b[32m    128\u001b[39m                 rotate_limit=\u001b[32m2\u001b[39m,\n\u001b[32m    129\u001b[39m                 border_mode=\u001b[32m0\u001b[39m,\n\u001b[32m    130\u001b[39m                 interpolation=\u001b[32m2\u001b[39m,\n\u001b[32m    131\u001b[39m                 value=(\u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m),\n\u001b[32m    132\u001b[39m                 p=\u001b[32m0.03\u001b[39m,\n\u001b[32m    133\u001b[39m             ),\n\u001b[32m    134\u001b[39m             alb.GridDistortion(\n\u001b[32m    135\u001b[39m                 distort_limit=\u001b[32m0.05\u001b[39m,\n\u001b[32m    136\u001b[39m                 border_mode=\u001b[32m0\u001b[39m,\n\u001b[32m    137\u001b[39m                 interpolation=\u001b[32m2\u001b[39m,\n\u001b[32m    138\u001b[39m                 value=(\u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m),\n\u001b[32m    139\u001b[39m                 p=\u001b[32m0.04\u001b[39m,\n\u001b[32m    140\u001b[39m             ),\n\u001b[32m    141\u001b[39m             alb.Compose(\n\u001b[32m    142\u001b[39m                 [\n\u001b[32m    143\u001b[39m                     alb.Affine(\n\u001b[32m    144\u001b[39m                         translate_px=(\u001b[32m0\u001b[39m, \u001b[32m5\u001b[39m), always_apply=\u001b[38;5;28;01mTrue\u001b[39;00m, cval=(\u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m)\n\u001b[32m    145\u001b[39m                     ),\n\u001b[32m    146\u001b[39m                     alb.ElasticTransform(\n\u001b[32m    147\u001b[39m                         p=\u001b[32m1\u001b[39m,\n\u001b[32m    148\u001b[39m                         alpha=\u001b[32m50\u001b[39m,\n\u001b[32m    149\u001b[39m                         sigma=\u001b[32m120\u001b[39m * \u001b[32m0.1\u001b[39m,\n\u001b[32m    150\u001b[39m                         alpha_affine=\u001b[32m120\u001b[39m * \u001b[32m0.01\u001b[39m,\n\u001b[32m    151\u001b[39m                         border_mode=\u001b[32m0\u001b[39m,\n\u001b[32m    152\u001b[39m                         value=(\u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m),\n\u001b[32m    153\u001b[39m                     ),\n\u001b[32m    154\u001b[39m                 ],\n\u001b[32m    155\u001b[39m                 p=\u001b[32m0.04\u001b[39m,\n\u001b[32m    156\u001b[39m             ),\n\u001b[32m    157\u001b[39m             alb.RandomBrightnessContrast(\u001b[32m0.1\u001b[39m, \u001b[32m0.1\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, p=\u001b[32m0.03\u001b[39m),\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m             \u001b[43malb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageCompression\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.07\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[32m    159\u001b[39m             alb.GaussNoise(\u001b[32m20\u001b[39m, p=\u001b[32m0.08\u001b[39m),\n\u001b[32m    160\u001b[39m             alb.GaussianBlur((\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), p=\u001b[32m0.03\u001b[39m),\n\u001b[32m    161\u001b[39m             alb.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n\u001b[32m    162\u001b[39m             ToTensorV2(),\n\u001b[32m    163\u001b[39m         ]\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m )\n\u001b[32m    166\u001b[39m test_transform = alb_wrapper(\n\u001b[32m    167\u001b[39m     alb.Compose(\n\u001b[32m    168\u001b[39m         [\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m     )\n\u001b[32m    173\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\albumentations\\core\\validation.py:105\u001b[39m, in \u001b[36mValidatedTransformMeta.__new__.<locals>.custom_init\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcustom_init\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     full_kwargs, param_names, strict = \u001b[38;5;28mcls\u001b[39m._process_init_parameters(original_init, args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     validated_kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_parameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdct\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInitSchema\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfull_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparam_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_default_values(signature(original_init).parameters)\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# Store and check invalid args\u001b[39;00m\n\u001b[32m    113\u001b[39m     invalid_args = [name_arg \u001b[38;5;28;01mfor\u001b[39;00m name_arg \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m name_arg \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m param_names \u001b[38;5;129;01mand\u001b[39;00m name_arg != \u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\albumentations\\core\\validation.py:71\u001b[39m, in \u001b[36mValidatedTransformMeta._validate_parameters\u001b[39m\u001b[34m(schema_cls, full_kwargs, param_names, strict)\u001b[39m\n\u001b[32m     69\u001b[39m     validated_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strict:\n",
      "\u001b[31mValueError\u001b[39m: 1 validation error for InitSchema\ncompression_type\n  Input should be 'jpeg' or 'webp' [type=literal_error, input_value=95, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.10/v/literal_error"
     ]
    }
   ],
   "source": [
    "doc = example_single_page(FILE_PATH, page_num=34, use_gpu=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tenv)",
   "language": "python",
   "name": "tenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
