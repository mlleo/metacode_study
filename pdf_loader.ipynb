{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80b54f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba3e03fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\aistudy\\metacode_study\\06-DocumentLoader\\data\\KDS140000Structure.pdf\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = r\"D:\\aistudy\\metacode_study\\06-DocumentLoader\\data\\KDS140000Structure.pdf\"\n",
    "print(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9176891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Nougat에 PDF를 직접 전달하여 compression_type 오류 우회\n",
    "이미지 변환 없이 PDF에서 바로 LaTeX 추출\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from typing import List, Dict, Optional, Generator\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Document:\n",
    "    \"\"\"RAG에서 사용할 문서 객체\"\"\"\n",
    "    page_content: str\n",
    "    metadata: Dict\n",
    "    \n",
    "    def __repr__(self):\n",
    "        preview = self.page_content[:100].replace('\\n', ' ')\n",
    "        return f\"Document(page={self.metadata.get('page')}, content='{preview}...')\"\n",
    "\n",
    "\n",
    "class NougatPDFLoader:\n",
    "    \"\"\"Nougat으로 PDF를 직접 처리하는 로더 (이미지 변환 불필요)\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"facebook/nougat-base\",\n",
    "        use_gpu: bool = True,\n",
    "        batch_size: int = 1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: Nougat 모델 이름\n",
    "            use_gpu: GPU 사용 여부\n",
    "            batch_size: 배치 크기 (메모리에 따라 조정)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.use_gpu = use_gpu and torch.cuda.is_available()\n",
    "        self.batch_size = batch_size\n",
    "        self.model = None\n",
    "        self.device = \"cuda\" if self.use_gpu else \"cpu\"\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Nougat 모델 로드\"\"\"\n",
    "        if self.model is not None:\n",
    "            return\n",
    "        \n",
    "        print(f\"Nougat 모델 로딩 중... (device: {self.device})\")\n",
    "        \n",
    "        try:\n",
    "            from nougat import NougatModel\n",
    "            from nougat.utils.checkpoint import get_checkpoint\n",
    "            \n",
    "            # 모델 로드\n",
    "            self.model = NougatModel.from_pretrained(self.model_name)\n",
    "            self.model = self.model.to(self.device)\n",
    "            self.model.eval()\n",
    "            \n",
    "            print(\"✓ 모델 로딩 완료\")\n",
    "        \n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Nougat이 설치되지 않았습니다.\\n\"\n",
    "                \"설치: pip install nougat-ocr\"\n",
    "            )\n",
    "    \n",
    "    def process_pdf_direct(\n",
    "        self, \n",
    "        pdf_path: str, \n",
    "        start_page: int = 0,\n",
    "        end_page: Optional[int] = None\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        PDF를 직접 처리 (이미지 변환 없이)\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: PDF 파일 경로\n",
    "            start_page: 시작 페이지 (0부터 시작)\n",
    "            end_page: 끝 페이지 (None이면 끝까지)\n",
    "        \n",
    "        Returns:\n",
    "            페이지별 텍스트 리스트\n",
    "        \"\"\"\n",
    "        from nougat.dataset.rasterize import rasterize_paper\n",
    "        from nougat.utils.dataset import LazyDataset\n",
    "        from nougat.postprocessing import markdown_compatible\n",
    "        from torch.utils.data import DataLoader\n",
    "        \n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "        \n",
    "        print(f\"\\nPDF 처리 시작: {os.path.basename(pdf_path)}\")\n",
    "        \n",
    "        # PDF를 Nougat Dataset으로 변환\n",
    "        try:\n",
    "            # rasterize_paper로 PDF를 이미지 리스트로 변환\n",
    "            images = rasterize_paper(\n",
    "                pdf_path,\n",
    "                return_pil=True,\n",
    "                pages=list(range(start_page, end_page if end_page else 9999))\n",
    "            )\n",
    "            \n",
    "            print(f\"총 {len(images)}개 페이지 발견\")\n",
    "            \n",
    "            # Dataset 생성\n",
    "            dataset = LazyDataset(\n",
    "                images,\n",
    "                partial(self.model.encoder.prepare_input, random_padding=False),\n",
    "            )\n",
    "            \n",
    "            # DataLoader 생성\n",
    "            dataloader = DataLoader(\n",
    "                dataset,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=False,\n",
    "                collate_fn=LazyDataset.ignore_none_collate\n",
    "            )\n",
    "            \n",
    "            # 추론 수행\n",
    "            predictions = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for idx, (sample, is_last_page) in enumerate(dataloader):\n",
    "                    if sample is None:\n",
    "                        continue\n",
    "                    \n",
    "                    # GPU로 이동\n",
    "                    if self.use_gpu:\n",
    "                        sample = sample.to(self.device)\n",
    "                    \n",
    "                    # 모델 추론\n",
    "                    model_output = self.model.inference(\n",
    "                        image_tensors=sample,\n",
    "                        early_stopping=True\n",
    "                    )\n",
    "                    \n",
    "                    # 후처리\n",
    "                    for output in model_output[\"predictions\"]:\n",
    "                        output = markdown_compatible(output)\n",
    "                        predictions.append(output)\n",
    "                    \n",
    "                    print(f\"  페이지 {idx + 1}/{len(images)} 완료\")\n",
    "            \n",
    "            return predictions\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return []\n",
    "    \n",
    "    def load_single_page(self, pdf_path: str, page_num: int) -> Document:\n",
    "        \"\"\"\n",
    "        단일 페이지 로드 (1부터 시작)\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: PDF 파일 경로\n",
    "            page_num: 페이지 번호 (1부터 시작)\n",
    "        \n",
    "        Returns:\n",
    "            Document 객체\n",
    "        \"\"\"\n",
    "        import time\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 페이지 인덱스는 0부터\n",
    "        results = self.process_pdf_direct(\n",
    "            pdf_path,\n",
    "            start_page=page_num - 1,\n",
    "            end_page=page_num\n",
    "        )\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        if not results:\n",
    "            raise RuntimeError(f\"페이지 {page_num} 처리 실패\")\n",
    "        \n",
    "        return Document(\n",
    "            page_content=results[0],\n",
    "            metadata={\n",
    "                'source': pdf_path,\n",
    "                'page': page_num,\n",
    "                'processing_time': processing_time\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def load_pages(\n",
    "        self,\n",
    "        pdf_path: str,\n",
    "        page_range: Optional[tuple] = None\n",
    "    ) -> Generator[Document, None, None]:\n",
    "        \"\"\"\n",
    "        여러 페이지를 스트리밍 방식으로 로드\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: PDF 파일 경로\n",
    "            page_range: (시작, 끝) 페이지 번호 (1부터 시작)\n",
    "        \n",
    "        Yields:\n",
    "            Document 객체\n",
    "        \"\"\"\n",
    "        import fitz\n",
    "        \n",
    "        # 전체 페이지 수 확인\n",
    "        doc = fitz.open(pdf_path)\n",
    "        total_pages = len(doc)\n",
    "        doc.close()\n",
    "        \n",
    "        if page_range is None:\n",
    "            start, end = 1, total_pages\n",
    "        else:\n",
    "            start, end = page_range\n",
    "            end = min(end, total_pages)\n",
    "        \n",
    "        print(f\"총 {total_pages}페이지 중 {start}~{end} 페이지 처리\")\n",
    "        \n",
    "        # 모델 로드\n",
    "        self.load_model()\n",
    "        \n",
    "        # 페이지 범위 처리 (0-based)\n",
    "        results = self.process_pdf_direct(\n",
    "            pdf_path,\n",
    "            start_page=start - 1,\n",
    "            end_page=end\n",
    "        )\n",
    "        \n",
    "        # Document 객체로 변환\n",
    "        for idx, text in enumerate(results):\n",
    "            page_num = start + idx\n",
    "            yield Document(\n",
    "                page_content=text,\n",
    "                metadata={\n",
    "                    'source': pdf_path,\n",
    "                    'page': page_num,\n",
    "                    'total_pages': total_pages\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    def load_all(\n",
    "        self,\n",
    "        pdf_path: str,\n",
    "        page_range: Optional[tuple] = None\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"\n",
    "        모든 페이지를 한 번에 로드\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: PDF 파일 경로\n",
    "            page_range: (시작, 끝) 페이지 번호\n",
    "        \n",
    "        Returns:\n",
    "            Document 객체 리스트\n",
    "        \"\"\"\n",
    "        return list(self.load_pages(pdf_path, page_range))\n",
    "    \n",
    "    def unload_model(self):\n",
    "        \"\"\"모델 언로드\"\"\"\n",
    "        if self.model is not None:\n",
    "            del self.model\n",
    "            self.model = None\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            print(\"✓ 모델 언로드 완료\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 사용 예제\n",
    "# ============================================================\n",
    "\n",
    "def example_single_page_direct(pdf_path: str, page_num: int = 1, use_gpu: bool = True):\n",
    "    \"\"\"\n",
    "    단일 페이지 처리 (PDF 직접 전달)\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: PDF 파일 경로\n",
    "        page_num: 페이지 번호 (1부터 시작)\n",
    "        use_gpu: GPU 사용 여부\n",
    "    \n",
    "    Returns:\n",
    "        Document 객체\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Nougat PDF 직접 처리 (이미지 변환 없음)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # 로더 초기화\n",
    "    loader = NougatPDFLoader(use_gpu=use_gpu)\n",
    "    \n",
    "    # 페이지 로드\n",
    "    try:\n",
    "        document = loader.load_single_page(pdf_path, page_num)\n",
    "        \n",
    "        print(f\"\\n문서 정보:\")\n",
    "        print(f\"  페이지: {document.metadata['page']}\")\n",
    "        print(f\"  처리시간: {document.metadata['processing_time']:.2f}초\")\n",
    "        print(f\"\\n내용 미리보기:\")\n",
    "        print(document.page_content[:500])\n",
    "        \n",
    "        return document\n",
    "    \n",
    "    finally:\n",
    "        loader.unload_model()\n",
    "\n",
    "\n",
    "def example_multiple_pages_direct(pdf_path: str, page_range: tuple = (1, 5), use_gpu: bool = True):\n",
    "    \"\"\"\n",
    "    여러 페이지 처리 (PDF 직접 전달)\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: PDF 파일 경로\n",
    "        page_range: (시작, 끝) 페이지 번호\n",
    "        use_gpu: GPU 사용 여부\n",
    "    \n",
    "    Returns:\n",
    "        Document 객체 리스트\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Nougat PDF 다중 페이지 처리\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # 로더 초기화\n",
    "    loader = NougatPDFLoader(use_gpu=use_gpu, batch_size=1)\n",
    "    \n",
    "    try:\n",
    "        documents = []\n",
    "        \n",
    "        for doc in loader.load_pages(pdf_path, page_range):\n",
    "            print(f\"\\n페이지 {doc.metadata['page']} 완료\")\n",
    "            print(f\"  내용 길이: {len(doc.page_content)} 문자\")\n",
    "            documents.append(doc)\n",
    "            \n",
    "            # 파일로 저장\n",
    "            with open(f\"page_{doc.metadata['page']}.md\", 'w', encoding='utf-8') as f:\n",
    "                f.write(doc.page_content)\n",
    "        \n",
    "        print(f\"\\n총 {len(documents)}개 문서 처리 완료\")\n",
    "        return documents\n",
    "    \n",
    "    finally:\n",
    "        loader.unload_model()\n",
    "\n",
    "\n",
    "# 필요한 import 추가\n",
    "from functools import partial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c5c3fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "예제 1: 단일 페이지 처리\n",
      "============================================================\n",
      "\n",
      "페이지 34 OCR 처리 중...\n",
      "  CLI 오류, API 모드로 전환: Nougat CLI 오류: D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:108: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform\n",
      "  super().__init__(always_apply=always_apply, p=p)\n",
      "D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:42: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform\n",
      "  super().__init__(always_apply=always_apply, p=p)\n",
      "D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:76: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform\n",
      "  super().__init__(always_apply=always_apply, p=p)\n",
      "D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:123: UserWarning: Argument(s) 'cval' are not valid for transform Affine\n",
      "  alb.Affine(shear={\"x\": (0, 3), \"y\": (-3, 0)}, cval=(255, 255, 255), p=0.03),\n",
      "D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:124: UserWarning: Argument(s) 'value' are not valid for transform ShiftScaleRotate\n",
      "  alb.ShiftScaleRotate(\n",
      "D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:134: UserWarning: Argument(s) 'value' are not valid for transform GridDistortion\n",
      "  alb.GridDistortion(\n",
      "D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:143: UserWarning: Argument(s) 'always_apply, cval' are not valid for transform Affine\n",
      "  alb.Affine(\n",
      "D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:146: UserWarning: Argument(s) 'alpha_affine, value' are not valid for transform ElasticTransform\n",
      "  alb.ElasticTransform(\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\albumentations\\core\\validation.py\", line 67, in _validate_parameters\n",
      "    config = schema_cls(**schema_kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\pydantic\\main.py\", line 214, in __init__\n",
      "    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "pydantic_core._pydantic_core.ValidationError: 1 validation error for InitSchema\n",
      "compression_type\n",
      "  Input should be 'jpeg' or 'webp' [type=literal_error, input_value=95, input_type=int]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"d:\\aistudy\\metacode_study\\tenv\\Scripts\\nougat.exe\\__main__.py\", line 2, in <module>\n",
      "  File \"D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\predict.py\", line 18, in <module>\n",
      "    from nougat import NougatModel\n",
      "  File \"D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\__init__.py\", line 7, in <module>\n",
      "    from .model import NougatConfig, NougatModel\n",
      "  File \"D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\model.py\", line 34, in <module>\n",
      "    from nougat.transforms import train_transform, test_transform\n",
      "  File \"D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py\", line 158, in <module>\n",
      "    alb.ImageCompression(95, p=0.07),\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\albumentations\\core\\validation.py\", line 105, in custom_init\n",
      "    validated_kwargs = cls._validate_parameters(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\albumentations\\core\\validation.py\", line 71, in _validate_parameters\n",
      "    raise ValueError(str(e)) from e\n",
      "ValueError: 1 validation error for InitSchema\n",
      "compression_type\n",
      "  Input should be 'jpeg' or 'webp' [type=literal_error, input_value=95, input_type=int]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "\n",
      "Nougat 모델 로딩 중... (device: cpu)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:108: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform\n",
      "  super().__init__(always_apply=always_apply, p=p)\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:42: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform\n",
      "  super().__init__(always_apply=always_apply, p=p)\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:76: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform\n",
      "  super().__init__(always_apply=always_apply, p=p)\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:123: UserWarning: Argument(s) 'cval' are not valid for transform Affine\n",
      "  alb.Affine(shear={\"x\": (0, 3), \"y\": (-3, 0)}, cval=(255, 255, 255), p=0.03),\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:124: UserWarning: Argument(s) 'value' are not valid for transform ShiftScaleRotate\n",
      "  alb.ShiftScaleRotate(\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:134: UserWarning: Argument(s) 'value' are not valid for transform GridDistortion\n",
      "  alb.GridDistortion(\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:143: UserWarning: Argument(s) 'always_apply, cval' are not valid for transform Affine\n",
      "  alb.Affine(\n",
      "d:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:146: UserWarning: Argument(s) 'alpha_affine, value' are not valid for transform ElasticTransform\n",
      "  alb.ElasticTransform(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "1 validation error for InitSchema\ncompression_type\n  Input should be 'jpeg' or 'webp' [type=literal_error, input_value=95, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.10/v/literal_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\albumentations\\core\\validation.py:67\u001b[39m, in \u001b[36mValidatedTransformMeta._validate_parameters\u001b[39m\u001b[34m(schema_cls, full_kwargs, param_names, strict)\u001b[39m\n\u001b[32m     66\u001b[39m schema_kwargs[\u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m] = strict\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m config = \u001b[43mschema_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mschema_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m validated_kwargs = config.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\pydantic\\main.py:214\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    213\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for InitSchema\ncompression_type\n  Input should be 'jpeg' or 'webp' [type=literal_error, input_value=95, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.10/v/literal_error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m doc = \u001b[43mexample_single_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFILE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage_num\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m34\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 491\u001b[39m, in \u001b[36mexample_single_page\u001b[39m\u001b[34m(pdf_path, page_num, dpi, use_gpu, use_cli)\u001b[39m\n\u001b[32m    488\u001b[39m loader = PDFLaTeXLoader(extractor, ocr)\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# 페이지 로드\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m document = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m문서 정보:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    494\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  페이지: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument.metadata[\u001b[33m'\u001b[39m\u001b[33mpage\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 387\u001b[39m, in \u001b[36mPDFLaTeXLoader.load_page\u001b[39m\u001b[34m(self, pdf_path, page_num)\u001b[39m\n\u001b[32m    384\u001b[39m page_image = \u001b[38;5;28mself\u001b[39m.extractor.extract_page(pdf_path, page_num)\n\u001b[32m    386\u001b[39m \u001b[38;5;66;03m# 2. OCR 처리 (메모리)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m ocr_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mocr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_page_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[38;5;66;03m# 3. Document 생성\u001b[39;00m\n\u001b[32m    390\u001b[39m document = Document(\n\u001b[32m    391\u001b[39m     page_content=ocr_result.text,\n\u001b[32m    392\u001b[39m     metadata={\n\u001b[32m   (...)\u001b[39m\u001b[32m    398\u001b[39m     }\n\u001b[32m    399\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 313\u001b[39m, in \u001b[36mNougatOCR.process_page_image\u001b[39m\u001b[34m(self, page_image)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m페이지 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_image.page_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m OCR 처리 중...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    311\u001b[39m start_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m text = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_image\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage_image\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m processing_time = time.time() - start_time\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m OCRResult(\n\u001b[32m    317\u001b[39m     page_num=page_image.page_num,\n\u001b[32m    318\u001b[39m     text=text,\n\u001b[32m    319\u001b[39m     processing_time=processing_time\n\u001b[32m    320\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 274\u001b[39m, in \u001b[36mNougatOCR.process_image\u001b[39m\u001b[34m(self, image, page_num)\u001b[39m\n\u001b[32m    272\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  CLI 오류, API 모드로 전환: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    273\u001b[39m         \u001b[38;5;28mself\u001b[39m.use_cli = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    276\u001b[39m     \u001b[38;5;66;03m# API 모드 (compression_type 오류 가능)\u001b[39;00m\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnougat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpostprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m markdown_compatible\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 280\u001b[39m, in \u001b[36mNougatOCR.process_image\u001b[39m\u001b[34m(self, image, page_num)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnougat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpostprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m markdown_compatible\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 176\u001b[39m, in \u001b[36mNougatOCR.load_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNougat 모델 로딩 중... (device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.device\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnougat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NougatModel\n\u001b[32m    177\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = NougatModel.from_pretrained(\u001b[38;5;28mself\u001b[39m.model_name)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.model.to(\u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mDonut\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mCopyright (c) 2022-present NAVER Corp.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mMIT License\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03mCopyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NougatConfig, NougatModel\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NougatDataset\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\model.py:34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig, PreTrainedModel\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnougat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpostprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m postprocess\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnougat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_transform, test_transform\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSwinEncoder\u001b[39;00m(nn.Module):\n\u001b[32m     38\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m    Encoder based on SwinTransformer\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    Set the initial weights and configuration with a pretrained SwinTransformer and then\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m \u001b[33;03m                      otherwise, `swin_base_patch4_window12_384` will be set (using `timm`).\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\nougat\\transforms.py:158\u001b[39m\n\u001b[32m    114\u001b[39m         img[img < \u001b[38;5;28mself\u001b[39m.lower] = \u001b[38;5;28mself\u001b[39m.value\n\u001b[32m    115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[32m    118\u001b[39m train_transform = alb_wrapper(\n\u001b[32m    119\u001b[39m     alb.Compose(\n\u001b[32m    120\u001b[39m         [\n\u001b[32m    121\u001b[39m             Bitmap(p=\u001b[32m0.05\u001b[39m),\n\u001b[32m    122\u001b[39m             alb.OneOf([Erosion((\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m)), Dilation((\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m))], p=\u001b[32m0.02\u001b[39m),\n\u001b[32m    123\u001b[39m             alb.Affine(shear={\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m: (-\u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m)}, cval=(\u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m), p=\u001b[32m0.03\u001b[39m),\n\u001b[32m    124\u001b[39m             alb.ShiftScaleRotate(\n\u001b[32m    125\u001b[39m                 shift_limit_x=(\u001b[32m0\u001b[39m, \u001b[32m0.04\u001b[39m),\n\u001b[32m    126\u001b[39m                 shift_limit_y=(\u001b[32m0\u001b[39m, \u001b[32m0.03\u001b[39m),\n\u001b[32m    127\u001b[39m                 scale_limit=(-\u001b[32m0.15\u001b[39m, \u001b[32m0.03\u001b[39m),\n\u001b[32m    128\u001b[39m                 rotate_limit=\u001b[32m2\u001b[39m,\n\u001b[32m    129\u001b[39m                 border_mode=\u001b[32m0\u001b[39m,\n\u001b[32m    130\u001b[39m                 interpolation=\u001b[32m2\u001b[39m,\n\u001b[32m    131\u001b[39m                 value=(\u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m),\n\u001b[32m    132\u001b[39m                 p=\u001b[32m0.03\u001b[39m,\n\u001b[32m    133\u001b[39m             ),\n\u001b[32m    134\u001b[39m             alb.GridDistortion(\n\u001b[32m    135\u001b[39m                 distort_limit=\u001b[32m0.05\u001b[39m,\n\u001b[32m    136\u001b[39m                 border_mode=\u001b[32m0\u001b[39m,\n\u001b[32m    137\u001b[39m                 interpolation=\u001b[32m2\u001b[39m,\n\u001b[32m    138\u001b[39m                 value=(\u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m),\n\u001b[32m    139\u001b[39m                 p=\u001b[32m0.04\u001b[39m,\n\u001b[32m    140\u001b[39m             ),\n\u001b[32m    141\u001b[39m             alb.Compose(\n\u001b[32m    142\u001b[39m                 [\n\u001b[32m    143\u001b[39m                     alb.Affine(\n\u001b[32m    144\u001b[39m                         translate_px=(\u001b[32m0\u001b[39m, \u001b[32m5\u001b[39m), always_apply=\u001b[38;5;28;01mTrue\u001b[39;00m, cval=(\u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m)\n\u001b[32m    145\u001b[39m                     ),\n\u001b[32m    146\u001b[39m                     alb.ElasticTransform(\n\u001b[32m    147\u001b[39m                         p=\u001b[32m1\u001b[39m,\n\u001b[32m    148\u001b[39m                         alpha=\u001b[32m50\u001b[39m,\n\u001b[32m    149\u001b[39m                         sigma=\u001b[32m120\u001b[39m * \u001b[32m0.1\u001b[39m,\n\u001b[32m    150\u001b[39m                         alpha_affine=\u001b[32m120\u001b[39m * \u001b[32m0.01\u001b[39m,\n\u001b[32m    151\u001b[39m                         border_mode=\u001b[32m0\u001b[39m,\n\u001b[32m    152\u001b[39m                         value=(\u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m255\u001b[39m),\n\u001b[32m    153\u001b[39m                     ),\n\u001b[32m    154\u001b[39m                 ],\n\u001b[32m    155\u001b[39m                 p=\u001b[32m0.04\u001b[39m,\n\u001b[32m    156\u001b[39m             ),\n\u001b[32m    157\u001b[39m             alb.RandomBrightnessContrast(\u001b[32m0.1\u001b[39m, \u001b[32m0.1\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, p=\u001b[32m0.03\u001b[39m),\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m             \u001b[43malb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageCompression\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.07\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[32m    159\u001b[39m             alb.GaussNoise(\u001b[32m20\u001b[39m, p=\u001b[32m0.08\u001b[39m),\n\u001b[32m    160\u001b[39m             alb.GaussianBlur((\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), p=\u001b[32m0.03\u001b[39m),\n\u001b[32m    161\u001b[39m             alb.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n\u001b[32m    162\u001b[39m             ToTensorV2(),\n\u001b[32m    163\u001b[39m         ]\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m )\n\u001b[32m    166\u001b[39m test_transform = alb_wrapper(\n\u001b[32m    167\u001b[39m     alb.Compose(\n\u001b[32m    168\u001b[39m         [\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m     )\n\u001b[32m    173\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\albumentations\\core\\validation.py:105\u001b[39m, in \u001b[36mValidatedTransformMeta.__new__.<locals>.custom_init\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcustom_init\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     full_kwargs, param_names, strict = \u001b[38;5;28mcls\u001b[39m._process_init_parameters(original_init, args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     validated_kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_parameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdct\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInitSchema\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfull_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparam_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_default_values(signature(original_init).parameters)\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# Store and check invalid args\u001b[39;00m\n\u001b[32m    113\u001b[39m     invalid_args = [name_arg \u001b[38;5;28;01mfor\u001b[39;00m name_arg \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m name_arg \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m param_names \u001b[38;5;129;01mand\u001b[39;00m name_arg != \u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aistudy\\metacode_study\\tenv\\Lib\\site-packages\\albumentations\\core\\validation.py:71\u001b[39m, in \u001b[36mValidatedTransformMeta._validate_parameters\u001b[39m\u001b[34m(schema_cls, full_kwargs, param_names, strict)\u001b[39m\n\u001b[32m     69\u001b[39m     validated_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strict:\n",
      "\u001b[31mValueError\u001b[39m: 1 validation error for InitSchema\ncompression_type\n  Input should be 'jpeg' or 'webp' [type=literal_error, input_value=95, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.10/v/literal_error"
     ]
    }
   ],
   "source": [
    "doc = example_single_page(FILE_PATH, page_num=34, dpi=300, use_gpu=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tenv)",
   "language": "python",
   "name": "tenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
