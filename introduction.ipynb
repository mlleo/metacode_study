{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNguFBfKktP7g0PWnIDBf23"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZkUe7jnNR4Bq","executionInfo":{"status":"ok","timestamp":1751177551018,"user_tz":-540,"elapsed":18783,"user":{"displayName":"jeongho shin","userId":"06257461622242954072"}},"outputId":"b3438e33-90ae-4d0b-c19c-54947f3e8c2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":[],"metadata":{"id":"Rv5fH4DwSf9X","executionInfo":{"status":"ok","timestamp":1751177753791,"user_tz":-540,"elapsed":7,"user":{"displayName":"jeongho shin","userId":"06257461622242954072"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["#### 기존 LLM (ChatGPT)의 한계점\n","##### ChatGPT는 최신 정보가 학습되어 있지 않습니다.\n","##### 개인이나 회사의 내부 데이터가 학습되어 있지 않아, 특정 도메인(개인 정보, 회사 내부 정보)에 대한 질문에는 기대하는 답변을 얻을 수 없습니다.\n","##### ChatGPT에 개인이나 회사 정보를 담은 문서를 업로드하면 보안상 문제가 될 수 있습니다.\n","##### 문서의 양이 많아질수록 할루시네이션 현상이 발생하기 쉽습니다.\n"],"metadata":{"id":"1g89rPGiUzU0"}},{"cell_type":"code","source":[],"metadata":{"id":"hVQcySfbVtp6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### RAG (Retriever-Augmented Generation)\n","##### RAG는 외부의 신뢰할 수 있는 지식 데이터베이스를 참조하여 최적화된 응답을 생성하는 기술입니다.\n","##### 최신 정보를 기반으로 답변할 수 있으며, LLM이 정보를 찾을 수 없는 경우 '검색' 기능을 활용해 답변을 제공할 수 있습니다.\n","##### 회사 내부에 데이터베이스를 구현함으로써 개인이나 회사의 내부 데이터를 참고하여 GPT가 답변할 수 있습니다.\n","##### 문서를 내부 데이터베이스에 저장하고 지속적으로 데이터를 축적할 수 있으며, 저장된 데이터베이스에서 원하는 정보를 검색한 후 이를 바탕으로 답변을 생성할 수 있습니다.\n","##### 저장된 데이터베이스에서 답변의 출처를 역으로 검색하고 검증하는 방식으로 할루시네이션 현상을 줄일 수 있습니다."],"metadata":{"id":"9NkSvj_GVoNe"}},{"cell_type":"markdown","source":["#### LangChain\n","##### LangChain은 대규모 언어 모델로 구동되는 애플리케이션을 개발하기 위한 프레임워크입니다.\n","##### 즉, GPT와 같은 언어 모델과 우리가 만들고자 하는 서비스나 프로세스를 쉽게 연결해 주는 도구입니다.\n","##### ChatGPT는 자체 RAG 시스템을 통해 답변을 제공하지만, 더 나은 답변을 위해 세부 알고리즘을 조정할 수 없다는 문제가 있습니다.\n","##### 따라서 LangChain을 통해 RAG의 모든 세부 프로세스를 빠르고 쉽게 구현하면 다양한 비즈니스 환경에서도 높은 수준의 성능에 도달할 수 있습니다.\n"],"metadata":{"id":"Y4uexMKBV1ne"}},{"cell_type":"markdown","source":["#### RAG 프로세스\n","##### 사전 단계\n","###### 1단계 : 문서 로드 (Document Load) : 외부 데이터 소스에서 필요한 문서를 불러와서 초기 처리를 합니다. 이것은 마치 학생이 공부하기 전에 책장에서 필요한 책을 여러 권 챙겨 오는 과정과 같습니다.\n","###### 2단계 : 텍스트 분할 (Text Split) : 로드된 문서를 처리 가능한 작은 단위인 청크(chunk)로 분할합니다. 두꺼운 책을 주제별로 나누어 Part나 Chapter로 구분하는 것과 유사합니다. 보통 분할된 청크 끝부분에서 맥락이 이어질 수 있도록 일부를 겹쳐서 분할합니다. (Chunk Overlap)\n","###### 3단계 : 임베딩 (Embedding) : 분할된 청크를 벡터 형태로 변환하여 문서의 의미를 수치화합니다. 자연어를 컴퓨터가 이해할 수 있는 수치로 변경하는 과정입니다.\n","###### 4단계 : 벡터 스토어 저장 : 임베딩된 청크를 데이터베이스에 저장합니다. 임베딩된 벡터들을 데이터베이스에 저장합니다. 이는 요약된 키워드를 색인으로 뽑아서 나중에 빠르게 찾을 수 있게 정리해 두는 과정입니다.\n"],"metadata":{"id":"tRLwkH8aWf1R"}},{"cell_type":"markdown","source":["##### RAG 프로세스 실행 단계\n","###### 5단계 : 리트리버 (Retreiver) : 질문이 주어지면, 이와 관련된 벡터를 벡터 데이터베이스에서 검색합니다. 질문에 가장 잘 맞는 책의 Chapter를 찾는 것과 유사합니다.\n","###### 6단계 : 프롬프트 (Prompt) : 검색된 정보를 바탕으로 언어 모델을 위한 질문을 구성합니다. 이는 정보를 바탕으로 어떻게 질문할지 결정하는 과정입니다.\n","###### 7단계 : LLM : 구성된 프롬프트를 사용하여 언어 모델이 답변을 생성합니다. 즉, 수집된 정보를 바탕으로 과제나 보고서를 작성하는 학생과 같습니다.\n","###### 8단계 : 체인 생성 : LCEL (Langchain Expression Language) 문법을 활용해 이전의 모든 과정을 하나의 파이프라인으로 묶어 주는 체인(Chain)을 생성합니다."],"metadata":{"id":"CrUopKyiXGqn"}},{"cell_type":"markdown","source":[],"metadata":{"id":"MelxNst0XOR_"}}]}